---
title: "Topic Modeling"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Topic Modelling
```{r topic model 1}

sparse_words <- fulltidy %>%
  mutate(Document = paste(ConvoId, Role, sep = "_")) %>%
  count(Document, Word, sort = TRUE) %>%
  cast_sparse(Document, Word, n)

library(stm)

convo_model <- stm(sparse_words, K = 40, init.type = "Spectral")
summary(convo_model)

## per topic per word probabilities
td_beta <- tidy(convo_model)

td_beta %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~topic, scales = "free_y")

## per document per topic probabilities

td_gamma <- tidy(convo_model, matrix = "gamma",
                 document_names = rownames(sparse_words))

td_gamma %>%
  ggplot(aes(gamma, fill = factor(topic))) +
  geom_histogram(show.legend = FALSE) +
  facet_wrap(~topic)

## find best number of topics
## https://juliasilge.com/blog/evaluating-stm/
## use estimateEffect for Role
## https://github.com/juliasilge/tidytext/issues/166
```

```{r}
plan(multiprocess)

many_models <- data_frame(K = c(10,15,20,25,35,45,55,70,85,100)) %>%
  mutate(topic_model = future_map(K, ~stm(sparse_words, K = .,
                                          verbose = FALSE)))

heldout <- make.heldout(sparse_words)

k_result <- many_models %>%
  mutate(exclusivity = map(topic_model, exclusivity),
         semantic_coherence = map(topic_model, semanticCoherence, sparse_words),
         eval_heldout = map(topic_model, eval.heldout, heldout$missing),
         residual = map(topic_model, checkResiduals, sparse_words),
         bound =  map_dbl(topic_model, function(x) max(x$convergence$bound)),
         lfact = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
         lbound = bound + lfact,
         iterations = map_dbl(topic_model, function(x) length(x$convergence$bound)))

# k_result

k_result %>%
  transmute(K,
            `Lower bound` = lbound,
            Residuals = map_dbl(residual, "dispersion"),
            `Semantic coherence` = map_dbl(semantic_coherence, mean),
            `Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout")) %>%
  gather(Metric, Value, -K) %>%
  ggplot(aes(K, Value, color = Metric)) +
  geom_line(size = 1.5, alpha = 0.7, show.legend = FALSE) +
  facet_wrap(~Metric, scales = "free_y") +
  labs(x = "K (number of topics)",
       y = NULL)
## between 60-70

k_result %>%
  select(K, exclusivity, semantic_coherence) %>%
  filter(K %in% c(15,40,60,70,100)) %>%
  unnest() %>%
  mutate(K = as.factor(K)) %>%
  ggplot(aes(semantic_coherence, exclusivity, color = K)) +
  geom_point(size = 2, alpha = 0.7) +
  labs(x = "Semantic coherence",
       y = "Exclusivity",
       title = "Comparing exclusivity and semantic coherence",
       subtitle = "Models with fewer topics have higher semantic coherence for more topics, but lower exclusivity")
```

