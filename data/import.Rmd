---
title: "Import the Data"
output: html_document
---
```{r in, include=FALSE, message=FALSE}
# library
library(tidyverse)
library(readxl)
library(tidytext)
library(broom)
library(stopwords)
library(dplyr)
library(skimr)
library(tidylo)

# set theme
theme_set(theme_classic())
```


```{r read, echo=FALSE, message=FALSE, include=FALSE}
# full_d for the full dialog, not annotated
full_d_raw = read_csv('data/FullData/full_dialog.csv',
         col_names = TRUE)

full_i_raw = read_csv('data/FullData/full_info.csv',
         col_names = TRUE) %>% 
  rename_with(~str_remove(.,"\\.x$"))
# anonymous fn ? regular expression (python/perl/real programming)

fullset = full_d_raw %>% 
  left_join(full_i_raw) %>% 
  select(
    ConvoId = B2,
    Turn = Turn,
    Role = B4, # (0 = persuader, 1 = persuadee)
    Dialogue = Unit,
    User = B3,
    NumTurn = B7,
    Donation = B6,
    everything()
    )

full_d_raw = full_d_raw %>% 
  select(
    ConvoId = B2,
    Turn = Turn,
    Role = B4, # (0 = persuader, 1 = persuadee)
    Dialogue = Unit
  )
# there were some really cool functions Julia used to clean up the data. One for smushing the two colums in the annotated set together, and one to get rid of the ".x" on the end of the identity variables. and a very cool funtion for looking at summary things


# ann_d for the full dialog, with annotations
ann_d_raw = read_xlsx('data/AnnotatedData/300_dialog.xlsx',
         col_names = TRUE)
# ann_i for the corresponding index file
ann_i_raw = read_xlsx('data/AnnotatedData/300_info.xlsx',
         col_names = TRUE)

annset = ann_d_raw %>% 
  left_join(ann_i_raw) %>%
  select(
    ConvoId = B2,
    Turn = Turn,
    Role = B4, # (0 means persuader, 1 means persuadee)
    Sentence = Unit,
    User = B3,
    Donation = B6,
    IntDonation = B5,
    NumTurn = B7,
    # Label1 = # concat(er_label_1,ee_label_1),
    # Label2 = # concat(er_label_2,ee_label_2),
    Neg = neg,
    Neu = neu,
    Pos = pos,
    everything()
  )

# annset = ann_d %>% select()
###

```


```{r tidyer, echo=FALSE, message=FALSE}
# What can we do with tidyr? Here are some transformations from chapter 1 of Silge's Text Mining With R to make token per row data. 

fulltidy = fullset %>% 
  select(ConvoId,
         User,
         Turn,
         Role,
         Dialogue) 
# putting the words in un_nest
fulltidy = full_d_raw %>% 
  inner_join(fullset) %>% 
    mutate(
    religion = factor(religion, levels = c("Catholic","Protestant","Atheist","Other religion"), labels = c("Catholic","Protestant","Atheist","Other religion")), 
    sex = factor(sex, levels = c("Male","Female","Other"),labels = c("Male","Female","Other")), 
    ideology = factor(ideology, levels =  c("Conservative","Moderate","Liberal"), labels = c("Conservative","Moderate","Liberal"), ordered = FALSE), 
    Role = factor(Role, levels = c("0","1"),labels = c("Persuader","Persuadee")), # adding labels!!
    edu = factor(edu, levels = c("Less than four-year college","Four-year college","Postgraduate"), labels = c("Less than four-year college","College","Postgraduate"))
  ) %>% 
  unnest_tokens(Word,Dialogue) %>% 
  # pulling out irrelevant words
  anti_join(get_stopwords(),by = c("Word" = "word")) 

```

