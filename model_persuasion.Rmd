---
title: "modelling persuasion"
author: "Christian Okoth"
output:
  word_document:
    toc: yes
  html_document:
    theme: simplex
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(cache = TRUE, cache.lazy = FALSE, warning = FALSE, 
                      message = FALSE, echo = TRUE, dpi = 180,
                      fig.width = 8, fig.height = 5)
library(ggplot2)
set.seed(2020)
library(ggthemes)
# set theme
theme_set(theme_solarized())
```
## Introduction

Introduction!

```{r library}
# tidying
library(tidyverse)
library(readxl)
library(broom)
library(dplyr)
# text analysis
library(stopwords)
library(tidytext)
library(skimr)
library(tidylo)
# unsupervised learning
library(furrr)
library(future)
library(stm)
```

## Data Import & Tidying

The data for this project come from MIT's Persuasion for Good dataset </link here> [the name and hyperlink]. I pulled the raw data from the repository, just `full_d_raw` and `full_i_raw`, which are the full dialogue and information about each participant. The raw datasets the basics. here's where I got it/how I did it process 
see in text read in code

```{r read1}
# full_d for the full dialog, not annotated
full_d_raw = read_csv('data/FullData/full_dialog.csv',
         col_names = TRUE)

full_i_raw = read_csv('data/FullData/full_info.csv',
         col_names = TRUE) %>% 
  rename_with(~str_remove(.,"\\.x$"))
# anonymous fn ? regular expression (python/perl/real programming)
```

Reading the data in, there were some interesting formatting choices. In `full_i_raw`, columns about personality traits and personal characteristics were marked as 'extrovert.x income.x conscientious.x religion.x' et cetera and there.

```{r read2}
## import data
fullset = full_d_raw %>% 
  left_join(full_i_raw) %>% 
  select(
    ConvoId = B2,
    Turn = Turn,
    Role = B4, # (0 = persuader, 1 = persuadee)
    Dialogue = Unit,
    User = B3,
    NumTurn = B7,
    Donation = B6,
    everything()
    )

## simplifying reference to columns
full_d_raw = full_d_raw %>% 
  select(
    ConvoId = B2,
    Turn = Turn,
    Role = B4, # (0 = persuader, 1 = persuadee)
    Dialogue = Unit
  )

# looking at individual sentences/instances to look at how standard the data are
fullset %>% slice_sample(n = 5) %>% pull(Dialogue)
```

The text container `Dialogue` is comprised of full exchanges, where each exchange is a typed exchange between participants. This is a value anywhere from a symbol to a sentence to multiple sentences. 

```{r read3}
# ann_d for the full dialog, with annotations
ann_d_raw = read_xlsx('data/AnnotatedData/300_dialog.xlsx',
         col_names = TRUE)
# ann_i for the corresponding index file
ann_i_raw = read_xlsx('data/AnnotatedData/300_info.xlsx',
         col_names = TRUE)
```

Reading in the annotated data.....

```{r read4}
annset = ann_d_raw %>% 
  left_join(ann_i_raw) %>%
  select(
    ConvoId = B2,
    Turn = Turn,
    Role = B4, # (0 means persuader, 1 means persuadee)
    Sentence = Unit,
    User = B3,
    Donation = B6,
    IntDonation = B5,
    NumTurn = B7,
    Neg = neg,
    Neu = neu,
    Pos = pos,
    everything()
  )
```

Joining the annotated data.....

```{r tidyer, include=FALSE, message=FALSE}
# What can we do with tidyr? Here are some transformations from chapter 1 of Silge's Text Mining With R to make token per row data. 

fulltidy = fullset %>% 
  select(ConvoId,
         User,
         Turn,
         Role,
         Dialogue) 
# putting the words in un_nest
fulltidy = full_d_raw %>% 
  inner_join(fullset) %>% 
    # assigning labels to the levels
    mutate(
    religion = factor(religion, levels = c("Catholic","Protestant","Atheist","Other religion"), labels = c("Catholic","Protestant","Atheist","Other religion")), 
    sex = factor(sex, levels = c("Male","Female","Other"),labels = c("Male","Female","Other Genders")), 
    ideology = factor(ideology, levels =  c("Conservative","Moderate","Liberal"), labels = c("Conservative","Moderate","Liberal"), ordered = FALSE), 
    Role = factor(Role, levels = c("0","1"),labels = c("Persuader","Persuadee")), # adding labels!!
    edu = factor(edu, levels = c("Less than four-year college","Four-year college","Postgraduate"), labels = c("Less than four-year college","College","Postgraduate"))
  ) %>% 

  # tidying the Dialogue by word
  unnest_tokens(Word,Dialogue) %>% 
  # pulling out irrelevant words
  anti_join(get_stopwords(),by = c("Word" = "word")) 

```

Here is where the tidying happens! So tidy text data is *one observation per row*, and in this text project, that means breaking up the text container `Dialogue` and having one word per row. I used `tidytext::unnest_tokens()` to automatically parse the text into single rows.

`stopwords::get_stopwords()` was an important part of this process. It removes words that do not usually contain meaningful information so that the tens of thousands of common little words won't interfere with our analysis.


## Exploratory Data Analysis

```{r fulltidy_plots01}
# most popular words
fulltidy %>% count(Word, sort = TRUE) %>% 
  filter(n > 1000) %>% 
  # reorder words by count
  ggplot(aes(fct_reorder(Word, n),n)) +
  geom_col() +
  coord_flip() +
  labs(x = NULL, title = "Most Common Words in Dialogue")
```

Using 'tidy' data, we can see which words were used the most during the all the conversations. Words 'children','save',and 'donate' were used the most out of any words, most likely because the charity is called 'Save the Children' and the participants are tasked with convincing people to donate.
```{r fullset_plot00, echo=FALSE}
# distributions for each personality trait (one of those bar plots that is stacked/filled)

# utterances per conversation
fullset %>% 
  count(ConvoId) %>% 
  ggplot(aes(n)) +
  geom_histogram(binwidth = 5) +
  labs(title = 'How long is each conversation?',x = '# of turns',y = '# of conversations',subtitle = 'On average, their conversations are 20 exchanges long.')
```



```{r fulltidy_plots03}
fulltidy %>% count(Word,Role, sort = TRUE) %>% 
  # filter(n > 500) %>% 
  slice_max(n,n = 25) %>% 
  ggplot(aes(Word,n, fill = as.factor(Role))) +
  geom_col() +
  coord_flip() +
  labs(title = "Top Words by Role", x = NULL, fill = NULL)
```

One of the major facets we examine is the participant's role in the conversation. Each person is assigned a role, the person asking for a donation and the person being asked to donate.

```{r fulltidy_plots04}
####Bar Charts (n) By Role####

fulltidy %>% 
  count(Word,Role,sort = TRUE) %>% 
  slice_max(n,n = 20) %>% 
  ggplot(aes(Word,n)) +
  geom_col(aes(fill = n),show.legend = FALSE) +
#  geom_text(aes(label = Word), check_overlap = TRUE, vjust = 1.5) +
  facet_wrap(~Role, scales = "free") +
  labs(x = NULL, y = 'count',title = "Most Common Words by Role", subtitle = "Persuaders talked waaaay more often...about the same things as the persuadees") +
  coord_flip()
```

This chart shows the most common words by Role. One would think, 'Ah this is it! We know what the most common words by Role are!' I thought the same thing. Alas, this is only the beginning. This chart is still important though! 

Text analysis is based around frequency, how often the words occur. And there is something meaningful to learn from the different methods of exploring frequency we go over in this analysis. Later, I'll explain some better ways to examine frequency.


### Donations Aside

```{r annset_plot01, echo=FALSE}
# plot multiple things against actual donation
# plot of actual donation v stated donation
# best way to represent the donation amount and the intended donation amount
annset %>% 
  filter(IntDonation < 200,
         Role == 1) %>% 
  ggplot() +
  geom_boxplot(aes(IntDonation)) +
  labs(title = "Show Me the Money", x = "stated donation amount (in USD)",subtitle = "Most people failed to get their partner to verbally commit to a donation amount")

annset %>% 
  #difference between IntDonation and Donation
  filter(IntDonation < 75,
         Role == 1) %>%
  ggplot(aes(Donation-IntDonation)) +
  geom_histogram(bins = 15) +
  labs(title = "But even out of those who did commit...",y = "# of participants", x = "difference in stated donation v actual donation amount (in USD)", subtitle = "Most either gave less or didn't actually give at all")

```

Most people actually donated how much they pledged to donate (which was nothing). As expected, some donated less, some donated more. Two big talkers promised to donate \$10,000 and \$500 respectively, but nothing came from it. Perhaps they weren't so persuasive after all...

So who was doing the donating and persuading anyways?

### Traits and Values

Let's get to know our participants! Here we have plots of their different values (the big five) and traits (education, sex, etc). These variables form the basis of our grouping variables later on, so it's a good idea to start here. This is also where I always start when playing with a dataset. While the dependent variable is always interesting, it's important to explore all the variables you have at the beginning.

```{r values_plot00, echo=FALSE}
##### values plots #####
# the big five [extrovert, agreeable, conscientious, neurotic, open]
full_i_raw %>% 
  select(B3,extrovert:open) %>% 
  pivot_longer(extrovert:open,names_to = "trait", values_to = "score") %>% 
  ggplot(aes(score, fill = trait)) +
  facet_wrap(~trait) +
  geom_histogram(bins = 5, show.legend = FALSE) +
  labs(title = 'The Big Five', y = '# of participants',subtitle = 'Participants\'s personalities tended to be highly agreeable, conscientious and open')
```

Something cool about this dataset is that each participant took three personality tests before the discussion. The big five, a major psychometric personality test, is the one we focus on in this analysis, but a further analysis may evaluate the sample using the Schwartz portrait, moral foundation, and decision making model. The big five model here shows us the different sorts of people we have

Now we'll look at our sample and their different traits. I made plots of each variable, simply visualizing the sample to understand what the best characteristics would be to group by. Rather than examining the entire population as a group, I want to know what traits are related to which words. To figure our the best traits to examine however, we look at the relationship between the different variables.

```{r traits_plot00, echo=FALSE}
##### traits plots ####
# one (or more) trait plots with other info
# religion, sex, ideology, role, education
# sex and role
fullset %>%
  count(sex,Role) %>% 
  replace_na(list(sex = 'Other')) %>% 
  mutate(Role = factor(Role, labels = c("Persuader","Persuadee"))) %>% 
  ggplot(aes(sex,n, fill = Role)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Role) +
  labs(title = "Who's talking?", subtitle = "Role was split up evenly across gender identity",y = '# of participants',x = "gender")
```

Role is arguably the most important grouping we have in this sample, because it tells us about the structure of the conversation. This grouping was the most obvious, because one could reasonably assume that the person being convinced and the person doing the convincing may speak differently. 

```{r traits_plot01, echo=FALSE}
# religion/ideology
full_i_raw %>%
  count(religion,ideology) %>% 
  mutate(ideology = factor(ideology, c("Conservative","Moderate","Liberal"))) %>% 
  filter(!is.na(ideology),!is.na(religion)) %>% 
  ggplot(aes(ideology,n,fill = religion)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~religion) +
  labs(title = "Who's Talking?",x = "political ideology",y = "# of participants", subtitle = "Christians tend to be more conservative and Atheists tend more liberal")
```

Higher proportions of atheists are liberal, as well as a large part of other religions. This tells us about the group makeups of ideology, where the conservative label will tend towards Christians and liberals will be mostly other religions and atheists.

```{r traits_plot02, echo=FALSE}
# dodge barchart ideology/religion
full_i_raw %>% 
  count(edu,ideology) %>% 
  # reoder education levels
  mutate(edu = factor(edu, c("Less than four-year college","Four-year college","Postgraduate")),
         ideology = factor(ideology, c("Conservative","Moderate","Liberal"))) %>% 
  filter(!is.na(edu), !is.na(ideology)) %>% 
  ggplot(aes(ideology,n,fill = ideology)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~edu) +
  labs(title = "Who's Talking?", x = 'political ideology', y = '# of participants', subtitle = "Ideological distributions hold across each level of education")
```

Most of our participants don't have a college degree, and for this sample, it seems education is not very related to political ideology. Here, we've learned a lot about our participants and their 

There are a number of traits that are not visualized here: income level, race, marital status. These variables were also interesting, but each also had other issues that made them a bad fit for this analysis. 

Back to the words!

```{r exit}
knitr::knit_exit()
```

## Rank and Frequency

Text cannot be added or subtracted. Text is analyzed by frequency, and there are a surprisingly large number of ways to analyze frequency. In this project, we look at an absolute relative document frequency and a Bayesian relative document frequency. But first, simple frequency!

```{r wordcount}
## preparation for Zipf's law and tf-idf
# two group by, one by conversation and one by total words in the sample
words1 = fullset %>% 
  select(ConvoId,
         Dialogue,
         NumTurn
        ) %>% 
  unnest_tokens(Word,Dialogue) %>% 
  count(ConvoId,Word,sort = TRUE, name = "Count")

words2 = words1 %>% 
  group_by(ConvoId) %>% 
  summarize(ctotal = sum(Count))

wordcount <- left_join(words1, words2)

# no grouping variable
wordcount1 = fullset %>%
  select(ConvoId,
         Dialogue,
         NumTurn
        ) %>%
  unnest_tokens(Word,Dialogue) %>%
  count(Word,sort = TRUE, name = "Count")
```

What do the distributions of the words look like compared to their conversation?

```{r word_frequency00}
wordcount %>% 
  ggplot(aes(Count/ctotal)) +
  geom_histogram(bins = 15) +
  labs(title = 'Word Usage per Conversation', x = "proportion of conversations", y = '# of words per conversation',subtitle = 'Many words are used infrequently and a few words are used very frequently') 
```

This was where I felt like I started learning about my data. 

```{r word_frequency01}
wordcount1 %>% 
  ggplot(aes(Count)) +
  geom_histogram(bins = 20) +
  scale_x_log10() +
  labs(title = 'Word Frequency', x = '# of occurences per word', y = '# of words',subtitle = 'Many words are said a few times, some words are said a lot')
```



## Zipf's Law

```{r frequency_rank}
# by convo_id
freq_by_rank <- wordcount %>%
  group_by(ConvoId) %>%
  mutate(rank = row_number(),
         `term frequency` = Count/ctotal)

# corpus, no by variable
freq_by_rank1 <- wordcount1 %>% 
  mutate(rank = row_number(),
         `term frequency` = Count)
```



```{r zipfs_law00}
# Zipf's law plot - group by ConvoId
freq_by_rank %>%
  ggplot(aes(rank, `term frequency`, color = ConvoId)) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
  scale_x_log10() +
  scale_y_log10()
# extremely noisy! not improved by removing 'color = '
```



```{r zipfs_law01}
# Zipf's law plot - corpus
freq_by_rank1 %>% 
  ggplot(aes(rank, `term frequency`)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
# very straight
```



```{r zipfs_law02}
rank_subset = freq_by_rank1 %>% 
  filter(rank > 100) # what would be the middle range of this data?

rank_model01 = lm(log10(`term frequency`) ~ log10(rank), data = freq_by_rank1)

rank_model02 = lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
```



## Term Frequency - Inverse Document Frequency

Term frequency - inverse document frequency is a statistic intended to measure the relative importance of a word within a document, compared to similar documents.This method is very common for search engines, efficiently sorting out which words are common across all websites and which are common only on certain pages. 
We can apply this method to investigate deeper into the data. We have already looked at which words are the most common according to role and the entire body of work. Now we can look at how common certain words are within each conversation. 

```{r tf_idf}
# there doesn't seem to be a way to evaluate tf_idf with this function without a grouping variable
# rank grouped by ConvoId
ranktf = freq_by_rank %>% 
  # mutate(total = 352376) %>% 
  bind_tf_idf(Word,ConvoId,Count)

# checking her out
ranktf %>%
  select(-rank) %>%
  arrange(desc(tf_idf))

# grouped by role - top 10 words by role
fulltidy %>% 
  count(Role,Word, sort = TRUE) %>% 
  bind_tf_idf(Word, Role,n) %>% 
  arrange(-tf_idf) %>% 
  group_by(Role) %>% 
  slice_max(tf_idf, n = 10)

fulltidy %>% 
  # mutate(Utterance = row_number()) %>% 
  unite('ConvoId', ConvoId,Role,sep = '--',remove = FALSE) %>% 
  count(ConvoId,Word, sort = TRUE) %>% 
  bind_tf_idf(Word, ConvoId,n) %>% 
  arrange(-tf_idf) %>% 
  separate(ConvoId,into = c('ConvoId','Role'),sep = '--') %>% 
  filter(n > 10) %>% 
  group_by(Role) %>% 
  slice_max(tf_idf, n = 10)


convo_tf_idf = fulltidy %>% 
  # mutate(Utterance = row_number()) %>% 
  unite('ConvoID', ConvoId,Role,sep = '--',remove = FALSE) %>% 
  count(ConvoID,Word, sort = TRUE) %>% 
  bind_tf_idf(Word,ConvoID,n) %>% 
  arrange(-tf_idf) %>% 
  # filter(n > 10) %>% 
  separate(ConvoID,into = c('ConvoId','Role'),sep = '--') %>% 
  group_by(Role) %>% 
  slice_max(tf_idf, n = 10)

role_words = convo_tf_idf %>% 
  group_by(Word) %>% 
  filter(sum(n) > 10) %>% # only keep words used over 50 times total
  ungroup() %>% 
  group_by(Role,Word) %>% # most distinct words by role
  # distinct(Word, Role, .keep_all = TRUE)
  # slice_max(tf_idf,n = 15)
  summarise(tf_idf = mean(tf_idf)) %>% # mean distinctive
  group_by(Role) %>% 
  slice_max(tf_idf,n = 15)

role_words %>% 
  ggplot(aes(tf_idf,Word)) +
  geom_col() +
  facet_wrap(~Role, scales = "free_y")

```

tf-idf, or *term frequency-inverse document frequency* in our case was an ineffective approach, as the document sizes (individual conversations) were too small. At an average of [avg words per ConvoId], there are not enough unique words to distinguish which words are valuable and which words are not. Some words had such low counts (typos, speaking styles), tf-idf was useless in identifying their importance as typos or important words.
Methodologically, this makes sense. Each conversation has a common goal, and while there are different persuasion styles, tf-idf will only tell us which **words** stand out in each conversation. The conversations were not particularly specialized, so the most we could utilize  tf-idf is observing surface-level differences between larger groupings, such as religion, race, or personality trait.
The mark of a good programmer is being able to use her tools. The mark of a great one is knowing each tools' limits and finding an alternative path. The next approach is log-odds.


## Log-Odds

```{r log_odds_transform}
# log-odds by interest trait: religion, sex, ideology, role, education
# log-odds grouped by religion
religion_lo = fulltidy %>%
  filter(!is.na(religion)) %>%
  count(Word, religion, sort = TRUE) %>%
  bind_log_odds(religion, Word, n) %>%
  arrange(-log_odds_weighted) %>%
  group_by(Word) %>%     ## only keep words used over 50 times total
  filter(sum(n) > 10) %>% # how robust is log-odds
  ungroup %>%
  group_by(religion) %>%
  slice_max(log_odds_weighted, n = 10)    ## most likely by religion

# log-odds grouped by sex
sex_lo = fulltidy %>%
  filter(!is.na(sex)) %>%
  count(Word, sex, sort = TRUE) %>%
  bind_log_odds(sex, Word, n) %>%
  arrange(-log_odds_weighted) %>%
  group_by(Word) %>%     ## only keep words used over 50 times total
  filter(sum(n) > 10) %>% # how robust is log-odds
  ungroup %>%
  group_by(sex) %>%
  slice_max(log_odds_weighted, n = 10)    ## most likely by sex

# log-odds grouped by ideology
ideology_lo = fulltidy %>%
  filter(!is.na(ideology)) %>%
  count(Word, ideology, sort = TRUE) %>%
  bind_log_odds(ideology, Word, n) %>%
  arrange(-log_odds_weighted) %>%
  group_by(Word) %>%     ## only keep words used over 50 times total
  filter(sum(n) > 10) %>% # how robust is log-odds
  ungroup %>%
  group_by(ideology) %>%
  slice_max(log_odds_weighted, n = 10)    ## most likely by ideology

# log-odds grouped by role
role_lo = fulltidy %>%
  filter(!is.na(Role)) %>%
  count(Word, Role, sort = TRUE) %>%
  bind_log_odds(Role, Word, n) %>%
  arrange(-log_odds_weighted) %>%
  group_by(Word) %>%     ## only keep words used over 50 times total
  filter(sum(n) > 10) %>% # how robust is log-odds
  ungroup %>%
  group_by(Role) %>%
  slice_max(log_odds_weighted, n = 10)    ## most likely by role

# log-odds grouped by role
edu_lo = fulltidy %>%
  filter(!is.na(edu)) %>%
  count(Word, edu, sort = TRUE) %>%
  bind_log_odds(edu, Word, n) %>%
  arrange(-log_odds_weighted) %>%
  group_by(Word) %>%     ## only keep words used over 50 times total
  filter(sum(n) > 10) %>% # how robust is log-odds
  ungroup %>%
  group_by(edu) %>%
  slice_max(log_odds_weighted, n = 10) ## most likely by education
```

Log Odds is a Bayesian technique comparing the frequency of the words in the text to the frequency of the words in each grouping. This technique differs from term frequency-inverse document frequency, because  tf-idf uses the frequency of the words and compares which words are different across documents, using a relative search to estimate importance. Log-odds approach is different, using [what is log-odds] to weight variable 

```{r log_odds_relgion plot}
religion_lo %>%
  ggplot(aes(log_odds_weighted, fct_reorder(Word, log_odds_weighted),fill = religion)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~religion, scales = "free_y") +
  labs(y = NULL)
```

Using log-odds to examine religion, we can learn a lot more about how people 

```{r log_odds_sex}
sex_lo %>%
  ggplot(aes(log_odds_weighted, fct_reorder(Word, log_odds_weighted),fill = sex)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sex, scales = "free") +
  labs(y = NULL)
```

For sex, we can see that [observations]

```{r log_odds_ideology}
ideology_lo %>%
  ggplot(aes(log_odds_weighted, fct_reorder(Word, log_odds_weighted),fill = ideology)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ideology, scales = "free_y") +
  labs(y = NULL)
```

With respect to political ideology, [observations]

```{r log_odds_role}
role_lo %>%
  ggplot(aes(log_odds_weighted, fct_reorder(Word, log_odds_weighted), fill = Role)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Role, scales = "free_y") +
  labs(y = NULL)
```

[observations] These plots look completely different, the persuaders tending towards specific, large words and nearly all of the persuadees using positively associated filler words, like 'oh', 'ok', 'sure'

```{r log_odds_edu}
edu_lo %>%
  ggplot(aes(log_odds_weighted, fct_reorder(Word, log_odds_weighted), fill = edu)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~edu, scales = "free_y") +
  labs(y = NULL)
```

Most words have a fairly uniform frequency within the groups, but it appears the postgraduates kept closely to the top words from the overall sample. Less than college found 'iam' and 'ur', shorthand for I am and you are. 'mexico' also made a comeback (liberal/atheist) and 'iam'/'ur' (moderate)


## Values Modelling

```{r values_modelling_agree}
agree_freq <- fulltidy %>%
  filter(!is.na(agreeable)) %>%
  count(agreeable, Word) %>%
  complete(agreeable, Word, fill = list(n = 0)) %>%
  group_by(agreeable) %>%
  mutate(value_total = sum(n)) %>%
  ungroup() %>%
  group_by(Word) %>%
  filter(sum(n) > 50) %>%
  ungroup()

agree_slopes <- agree_freq %>%
  nest(tiny_tibbles = c(agreeable, n, value_total)) %>%
  mutate(models = map(tiny_tibbles, ~glm(cbind(n, value_total) ~ agreeable, data = ., family = "binomial"))) %>%
  mutate(models = map(models, tidy)) %>%
  select(-tiny_tibbles) %>%
  unnest(models) %>%
  filter(term == "agreeable") %>%
  mutate(p.value = p.adjust(p.value))

agree_slopes %>%
  slice_min(p.value, n = 9) %>%
  inner_join(agree_freq) %>%
  ggplot(aes(agreeable, n / value_total)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~Word) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "Agreeableness score",
       y = "Word frequency")
```



```{r values_modelling_conscience}
conscience_freq <- fulltidy %>%
  filter(!is.na(conscientious)) %>%
  count(conscientious, Word) %>%
  complete(conscientious, Word, fill = list(n = 0)) %>%
  group_by(conscientious) %>%
  mutate(value_total = sum(n)) %>%
  ungroup() %>%
  group_by(Word) %>%
  filter(sum(n) > 50) %>%
  ungroup()

conscience_slopes <- conscience_freq %>%
  nest(tiny_tibbles = c(conscientious, n, value_total)) %>%
  mutate(models = map(tiny_tibbles, ~glm(cbind(n, value_total) ~ conscientious, data = ., family = "binomial"))) %>%
  mutate(models = map(models, tidy)) %>%
  select(-tiny_tibbles) %>%
  unnest(models) %>%
  filter(term == "conscientious") %>%
  mutate(p.value = p.adjust(p.value))

conscience_slopes %>%
  slice_min(p.value, n = 9) %>%
  inner_join(conscience_freq) %>%
  ggplot(aes(conscientious, n / value_total)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~Word) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "Conscientiousness score",
       y = "Word frequency")

```



```{r values_modelling_extrovert}
extrovert_freq <- fulltidy %>%
  filter(!is.na(extrovert)) %>%
  count(extrovert, Word) %>%
  complete(extrovert, Word, fill = list(n = 0)) %>%
  group_by(extrovert) %>%
  mutate(value_total = sum(n)) %>%
  ungroup() %>%
  group_by(Word) %>%
  filter(sum(n) > 50) %>%
  ungroup()

extrovert_slopes <- extrovert_freq %>%
  nest(tiny_tibbles = c(extrovert, n, value_total)) %>%
  mutate(models = map(tiny_tibbles, ~glm(cbind(n, value_total) ~ extrovert, data = ., family = "binomial"))) %>%
  mutate(models = map(models, tidy)) %>%
  select(-tiny_tibbles) %>%
  unnest(models) %>%
  filter(term == "extrovert") %>%
  mutate(p.value = p.adjust(p.value))

extrovert_slopes %>%
  slice_min(p.value, n = 9) %>%
  inner_join(extrovert_freq) %>%
  ggplot(aes(extrovert, n / value_total)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~Word) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "Extroversion score",
       y = "Word frequency")
```



```{r values_modelling_neurotic}
neurotic_freq <- fulltidy %>%
  filter(!is.na(neurotic)) %>%
  count(neurotic, Word) %>%
  complete(neurotic, Word, fill = list(n = 0)) %>%
  group_by(neurotic) %>%
  mutate(value_total = sum(n)) %>%
  ungroup() %>%
  group_by(Word) %>%
  filter(sum(n) > 50) %>%
  ungroup()

neurotic_slopes <- neurotic_freq %>%
  nest(tiny_tibbles = c(neurotic, n, value_total)) %>%
  mutate(models = map(tiny_tibbles, ~glm(cbind(n, value_total) ~ neurotic, data = ., family = "binomial"))) %>%
  mutate(models = map(models, tidy)) %>%
  select(-tiny_tibbles) %>%
  unnest(models) %>%
  filter(term == "neurotic") %>%
  mutate(p.value = p.adjust(p.value))

neurotic_slopes %>%
  slice_min(p.value, n = 9) %>%
  inner_join(neurotic_freq) %>%
  ggplot(aes(neurotic, n / value_total)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~Word) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "Neuroticsm score",
       y = "Word frequency")
```



```{r values_modelling_open}
open_freq <- fulltidy %>%
  filter(!is.na(open)) %>%
  count(open, Word) %>%
  complete(open, Word, fill = list(n = 0)) %>%
  group_by(open) %>%
  mutate(value_total = sum(n)) %>%
  ungroup() %>%
  group_by(Word) %>%
  filter(sum(n) > 50) %>%
  ungroup()

open_slopes <- open_freq %>%
  nest(tiny_tibbles = c(open, n, value_total)) %>%
  mutate(models = map(tiny_tibbles, ~glm(cbind(n, value_total) ~ open, data = ., family = "binomial"))) %>%
  mutate(models = map(models, tidy)) %>%
  select(-tiny_tibbles) %>%
  unnest(models) %>%
  filter(term == "open") %>%
  mutate(p.value = p.adjust(p.value))

open_slopes %>%
  slice_min(p.value, n = 9) %>%
  inner_join(open_freq) %>%
  ggplot(aes(open, n / value_total)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~Word) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "Openess score",
       y = "Word frequency")
```


## Topic Modelling

Unsupervised learning. We used a bunch of traits to group our data before, but what if those groups were meaningless? Are there better or more homogeneous groups of text that we can use? The answer is yes, and machine leanring is going to help us find them.

```{r topic_model01}
## casting the text as a sparse matrix
sparse_words <- fulltidy %>%
  mutate(Document = paste(ConvoId, Role, sep = "_")) %>%
  count(Document, Word, sort = TRUE) %>%
  cast_sparse(Document, Word, n)

library(stm)

## the model! the learning happens here
convo_model <- stm(sparse_words, K = 40, init.type = "Spectral")
summary(convo_model)

## per topic per word probabilities
td_beta <- tidy(convo_model)

td_beta %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~topic, scales = "free_y")

## per document per topic probabilities

td_gamma <- tidy(convo_model, matrix = "gamma",
                 document_names = rownames(sparse_words))

td_gamma %>%
  ggplot(aes(gamma, fill = factor(topic))) +
  geom_histogram(show.legend = FALSE) +
  facet_wrap(~topic)

```



```{r topic_model02}
plan(multiprocess)

many_models <- data_frame(K = c(10,15,20,25,35,45,55,70,85,100)) %>%
  mutate(topic_model = future_map(K, ~stm(sparse_words, K = .,
                                          verbose = FALSE)))

heldout <- make.heldout(sparse_words)

k_result <- many_models %>%
  mutate(exclusivity = map(topic_model, exclusivity),
         semantic_coherence = map(topic_model, semanticCoherence, sparse_words),
         eval_heldout = map(topic_model, eval.heldout, heldout$missing),
         residual = map(topic_model, checkResiduals, sparse_words),
         bound =  map_dbl(topic_model, function(x) max(x$convergence$bound)),
         lfact = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
         lbound = bound + lfact,
         iterations = map_dbl(topic_model, function(x) length(x$convergence$bound)))

# k_result

k_result %>%
  transmute(K,
            `Lower bound` = lbound,
            Residuals = map_dbl(residual, "dispersion"),
            `Semantic coherence` = map_dbl(semantic_coherence, mean),
            `Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout")) %>%
  gather(Metric, Value, -K) %>%
  ggplot(aes(K, Value, color = Metric)) +
  geom_line(size = 1.5, alpha = 0.7, show.legend = FALSE) +
  facet_wrap(~Metric, scales = "free_y") +
  labs(x = "K (number of topics)",
       y = NULL)
```

LB: Convergence
SC: Topic Quality
K =? 60-70
