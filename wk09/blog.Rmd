RStudio Mentorship Experience

Working with Dr. Silge was incredible. 
Her mentoring style was highly interactive. Imagine a mix between live coding and dialogue back and forth, debug in real time (that was very cool, something you don't realize you need to know) and I could learn from asking questions about the process of watching her pull code she knew while exploring tools, options, manuals, and error messages. 
very explorative, I had just enough guidance to point me in the right direction. 
I learned a lot about reproducibility, part of my system that I didn't have. 
Asking questions in this environment was empowering, not 
All of this is before I learned about text processing. My R journey was largely self taught, and I hadn't realized how much I was missing from my process. 
I think my favorite part of the experience is when we explored the term-frequency inverse document frequency. I had just finished making several dynamic plots of the participant variables and the frequency plots all looked very good. Then she brought up some information about the topic and showed me how to do some base analysis with tf-idf. So I spent the week looking over it, trying to make some more plots using pieces of her code, however I could not get a lot of the plots to make much sense. The next week, we realized that it wasn't going to work. 
The combination of knowledge and ability it requires to change strategies is immense. First you have to try and fix what is wrong. Then if that doesn't work, you have to understand why it's wrong. Once you do that, you pull on knowledge from experience and knowing where to look and how to find what you need. Then you can pivot to a new strategy that will accomodate the failings of the former approach. 
We tried everything: regrouping the variables, completing any incomplete lines, adjusting the code approach (percent vs absolute). That work only returned more garbled answers. Turn to the documentation: how does the tf-idf function work in R? How does it work outside of R? What are the princple assumptions and requirements of the tf-idf approach? As it turns out, tf-idf wasn't broken, it was simply an inappropriate solution to our data. term frequency-inverse document frequency is designed to handle documents with large counts of words. Rather than discerning which conversations centered around disaster relief or religion, tf-idf discerned which words were the least likely to show up in any conversation, and 'rupees'is pretty uncommon in the dataset. But even between thousands of conversations, search engine level tf-idf couldn't identify patterns within each group of conversations. So the issue was with the relative raw counts. Dr. Silge immediately thought to another technique she was familiar with, log-odds, frequently used in logistic regression.  
The text processing part was really fun, I learned a lot about how to use a ggplot to make some communicative visualizations, and how to decipher text as individual words. Finding patterns in the data is the point of reorganizing data is to understand it. We went through multiple word processes, including regression, and a bunch of new approaches, like tf-idf, and log-odds. Trying to see what the words were telling me was always a struggle though. Text data was unfamiliar to me (despite my English background), but there is a rhythm to trying to understand words in context. That process was helpful for understanding the intuition in analysis